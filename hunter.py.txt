import requests
from bs4 import BeautifulSoup
import json
import datetime

class A11yHunter:
    def __init__(self):
        self.headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        self.all_jobs = []

    def fetch_a11yjobs(self):
        """Busca en el portal nicho A11yJobs"""
        try:
            res = requests.get("https://a11yjobs.com", headers=self.headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            for job in soup.select('.job-card')[:10]:
                self.all_jobs.append({
                    "title": job.select_one('.job-title').get_text(strip=True),
                    "company": job.select_one('.company-name').get_text(strip=True),
                    "url": "https://a11yjobs.com" + job.select_one('a')['href'],
                    "source": "A11yJobs",
                    "date": "Reciente"
                })
        except: print("Error en A11yJobs")

    def fetch_linkedin_public(self):
        """Busca en LinkedIn sin necesidad de login (vía query pública)"""
        url = "https://www.linkedin.com/jobs/search?keywords=Accessibility%20Engineer&location=Worldwide&f_TPR=r86400"
        try:
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            for job in soup.select('.base-card')[:10]:
                self.all_jobs.append({
                    "title": job.select_one('.base-search-card__title').get_text(strip=True),
                    "company": job.select_one('.base-search-card__subtitle').get_text(strip=True),
                    "url": job.select_one('a')['href'].split('?')[0],
                    "source": "LinkedIn",
                    "date": "Últimas 24h"
                })
        except: print("Error en LinkedIn")

    def fetch_indeed_a11y(self):
        """Busca en Indeed roles de Accesibilidad"""
        url = "https://www.indeed.com/jobs?q=web+accessibility&fromage=1"
        try:
            res = requests.get(url, headers=self.headers)
            soup = BeautifulSoup(res.text, 'html.parser')
            for job in soup.select('.job_seen_pedal')[:5]:
                self.all_jobs.append({
                    "title": job.select_one('.jobTitle').get_text(strip=True),
                    "company": job.select_one('.companyName').get_text(strip=True),
                    "url": "https://www.indeed.com" + job.select_one('a')['href'],
                    "source": "Indeed",
                    "date": "Hoy"
                })
        except: print("Error en Indeed")

    def save_results(self):
        with open('jobs_data.json', 'w', encoding='utf-8') as f:
            json.dump(self.all_jobs, f, indent=4, ensure_ascii=False)

# Ejecución
hunter = A11yHunter()
hunter.fetch_a11yjobs()
hunter.fetch_linkedin_public()
hunter.fetch_indeed_a11y()
hunter.save_results()
print(f"Total: {len(hunter.all_jobs)} empleos listos para aplicar.")